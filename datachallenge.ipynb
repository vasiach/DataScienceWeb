{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is given a dataset that includes information about online purchases of users in an online-shop to predict whether or not the user will purchase a beverage in the next order. \n",
    "\n",
    "Our task is therefore to perform binary classification (since we are talking about 2 classes) and make predictions  by extracting features from the dataset and choosing the appropriate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Feature Extraction "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Orders size:(3346083, 10)\n",
    "Orders priors size:(32434489, 6)\n",
    "We have 49688 products out of which 4365 are beverages\n",
    "We have 21 departments and 134 aisles. We are intersted in department 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract features for our model we first need to explore the dataset and consider habits of the users described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read train test data\n",
    "X_train=pd.read_csv(\"data/X_train.csv\")\n",
    "y_train=pd.read_csv(\"data/y_train.csv\")\n",
    "y_train.drop('order_id', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = pd.read_csv('data/orders.csv')\n",
    "products = pd.read_csv('data/products.csv')\n",
    "orders_priors = pd.read_csv('data/order_products__prior.csv')\n",
    "departments = pd.read_csv('data/departments.csv')\n",
    "aisles = pd.read_csv('data/aisles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of aisles and departments\n",
    "num_aisles= aisles.aisle_id.nunique()\n",
    "num_deps = departments.department_id.nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to dummy values\n",
    "X_train = X_train.drop(['order_dow', 'order_hour_of_day'], axis=1)\n",
    "#X_train= pd.get_dummies(X_train, prefix=[\"d\", \"h\"], columns=['order_dow', 'order_hour_of_day'])\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Beverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# products in department 7\n",
    "products_bev = products[products['department_id']==7]\n",
    "products_bev_id = list(products_bev.product_id.values)\n",
    "num_aisles_7 = products_bev.aisle_id.nunique()\n",
    "num_bev = products_bev.product_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  prior orders of department 7\n",
    "orders_priors_bev = orders_priors[orders_priors['product_id'].isin(products_bev_id)]\n",
    "orders_prior_id_bev = list(orders_priors_bev.order_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders of department 7\n",
    "orders_bev = orders[orders['order_id'].isin(orders_prior_id_bev)]\n",
    "orders_bev.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders per User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user with many orders as well as many orders that involve beverages is more likely to purchase a beverage in the next order. Also a user with a big ratio of beverages orders over orders seems to order beverages frequently and therefore this seems to be a good feature for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count orders of department 7 for every user\n",
    "count_ord_bev = orders_bev.groupby('user_id')['order_id'].count().reset_index()\n",
    "count_ord_bev.rename(columns={'order_id':'order_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count orders of all departments for every user\n",
    "count_ord = orders.groupby('user_id')['order_id'].count().reset_index()\n",
    "count_ord.rename(columns={'order_id':'orders_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_ord_bev = count_ord_bev.merge(count_ord, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratio of orders with beverages to orders of all deps\n",
    "count_ord_bev['orders_bev_ratio']= count_ord_bev['order_count']/count_ord_bev['orders_count']\n",
    "count_ord_bev.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 2 bev_orders/orders per user\n",
    "X_train = X_train.merge(count_ord_bev[['user_id', 'orders_bev_ratio']], on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 3 beverages orders per user\n",
    "X_train = X_train.merge(count_ord_bev[['user_id', 'order_count']], on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 4 orders per user\n",
    "X_train = X_train.merge(count_ord_bev[['user_id', 'orders_count']], on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beverages per basket per user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a user has a big ratio of beverages per basket this seems to be a good indicator that he is more likely to purchase a beverage in his next order. The same applies for a user with a high average of beverages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate size of each order\n",
    "orders_priors['size_of_order']=orders_priors.groupby('order_id')['add_to_cart_order'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add size of basket \n",
    "orders_priors_bev = orders_priors_bev.merge(orders_priors[['order_id', 'size_of_order']].drop_duplicates(subset=['order_id']), on='order_id', how='left')\n",
    "orders_bev = orders_bev.merge(orders_priors_bev[['order_id', 'size_of_order']].drop_duplicates(subset=['order_id']), on='order_id', how='left')\n",
    "orders_bev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate total beverages count per order\n",
    "beverages_count= orders_priors_bev.groupby('order_id')['product_id'].count().reset_index()\n",
    "beverages_count = beverages_count.rename(columns={'product_id':'beverages_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_priors_bev = orders_priors_bev.merge(beverages_count, on='order_id', how='left')\n",
    "orders_bev = orders_bev.merge(beverages_count, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate beverages per basket\n",
    "orders_priors_bev['bev_per_basket']= np.where(orders_priors_bev['beverages_count'] < 1, orders_priors_bev['beverages_count'], orders_priors_bev['beverages_count']/orders_priors_bev['size_of_order'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(orders_priors_bev[['order_id', 'bev_per_basket']].drop_duplicates(subset=['order_id']), on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average beverage per basket per user\n",
    "bev_per_basket = orders_bev.groupby('user_id')['bev_per_basket'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 5 average beverage per basket per user\n",
    "X_train = X_train.merge(bev_per_basket, on='user_id', how='left')\n",
    "X_train  = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean beverages count per user\n",
    "beverages = orders_bev.groupby('user_id')['beverages_count'].mean().reset_index()\n",
    "beverages = beverages.rename(columns={'beverages_count':'mean_beverage_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 6 mean beverages count per user\n",
    "X_train = X_train.merge(beverages, on='user_id', how='left')\n",
    "X_train  = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = orders.merge(count_ord, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(count_ord_bev, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 7 size of order\n",
    "X_train = X_train.merge(orders_bev[['user_id','size_of_order' ]].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train  = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordered beverages per user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of reordered beverages per user shows how frequently the user prefers the same beverages and tends to rebuy them which is a good predictor. In this basis we can consider certain features to add to our model. Other than the average of reordered beverages per user, we can consider the reorder beverages per basket meaning how many of the products in an order are reordered beverages at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many of the beverages are reordered by order_id\n",
    "reordered_beverages = orders_priors_bev.groupby('order_id')['reordered'].sum().reset_index()\n",
    "reordered_beverages = reordered_beverages.rename(columns={'reordered':'reordered_bev_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(reordered_beverages, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate beverage reorder ratio for every order\n",
    "orders_bev['reorder_bev_ratio']= orders_bev['reordered_bev_count']/orders_bev['beverages_count']\n",
    "orders_bev['reorder_bev_basket_rt']=orders_bev['reordered_bev_count']/orders_bev['size_of_order']\n",
    "orders_bev.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate user average ratio of beverages that are reordered\n",
    "user_reorder_bev_ratio = orders_bev.groupby('user_id')['reordered_bev_count'].mean().reset_index()\n",
    "user_reorder_bev_ratio = user_reorder_bev_ratio.rename(columns={'reordered_bev_count':'user_bev_reorder_rt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate user average ratio of bev per basket that are reordered\n",
    "user_reorder_bev_basket_rt = orders_bev.groupby('user_id')['reorder_bev_basket_rt'].mean().reset_index()\n",
    "user_reorder_bev_basket_rt = user_reorder_bev_basket_rt.rename(columns={'reorder_bev_basket_rt':'user_bev_basket_reorder_rt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(user_reorder_bev_ratio[['user_id', 'user_bev_reorder_rt']], on='user_id', how='left')\n",
    "orders_bev = orders_bev.merge(user_reorder_bev_basket_rt[['user_id', 'user_bev_basket_reorder_rt']], on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 8 user average ratio of beverages that are reordered\n",
    "X_train = X_train.merge(user_reorder_bev_ratio, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 9 user average ratio of bev per basket that are reordered\n",
    "X_train = X_train.merge(user_reorder_bev_basket_rt, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Reorder per user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative to the ratio of beverages that are reordered by user this feature, the ratio of products that are reordered per user also shows a measure of habbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many of the products are reordered by order_id\n",
    "reordered_prod = orders_priors.groupby('order_id')['reordered'].sum().reset_index()\n",
    "reordered_prod = reordered_prod.rename(columns={'reordered':'reordered_prod_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_count= orders_priors.groupby('order_id')['product_id'].count().reset_index()\n",
    "product_count = product_count.rename(columns={'product_id':'product_count'})\n",
    "orders = orders.merge(product_count, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = orders.merge(reordered_prod, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders['reorder_ratio_all']= np.where(orders['reordered_prod_count']<1, orders['reordered_prod_count'], orders['reordered_prod_count']/orders['product_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(orders[['order_id', 'reordered_prod_count', 'reorder_ratio_all']].drop_duplicates(subset=['order_id']), on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reorder_ratio = orders_bev.groupby('user_id')['reordered_prod_count'].mean().reset_index()\n",
    "user_reorder_ratio = user_reorder_ratio.rename(columns={'reordered_prod_count':'user_prod_reorder_rt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(user_reorder_ratio[['user_id', 'user_prod_reorder_rt']], on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 10 average user product reorder ratio \n",
    "X_train = X_train.merge(user_reorder_ratio, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Average interval between days "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency in days the user purchases beverages and products as well as the ratio between those seems to provide information about the user's behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average interval between buying beverages per user\n",
    "average_order_days_bev = orders_bev.groupby('user_id')['days_since_prior_order'].mean().reset_index()\n",
    "average_order_days_bev = average_order_days_bev.rename(columns={'days_since_prior_order':'avg_bev_days_since_prior'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average interval between buying products per user\n",
    "avg_order_days = orders.groupby('user_id')['days_since_prior_order'].mean().reset_index()\n",
    "avg_order_days = avg_order_days.rename(columns={'days_since_prior_order':'avg_days_since_prior'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_order_days_bev = average_order_days_bev.merge(avg_order_days, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average interval ratio bev/prod\n",
    "average_order_days_bev['avg_days_bev']=average_order_days_bev['avg_bev_days_since_prior']/average_order_days_bev['avg_days_since_prior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 11 average interval ratio bev/prod\n",
    "X_train = X_train.merge(average_order_days_bev[['user_id', 'avg_days_bev']], on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 12 average interval between buying products per user\n",
    "X_train = X_train.merge(average_order_days_bev[['user_id', 'avg_days_since_prior']], on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder mean per days since prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative to the previous feature, this feature aims to give us information on whether there is a relationship between the days that have passed since the prior order and the reordered ratio of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average mean reorder per days since prior order\n",
    "orders_prod_days = orders_bev.merge(orders_priors_bev, on='order_id', how='left')\n",
    "grouped_days_df = orders_prod_days.groupby('days_since_prior_order')['reordered'].mean().reset_index()\n",
    "grouped_days_df = grouped_days_df.rename(columns={'reordered':'days_reorder'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(grouped_days_df, on='days_since_prior_order', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user average mean reorder per days since prior order\n",
    "user_days_reorder = orders_bev.groupby('user_id')['days_reorder'].mean().reset_index()\n",
    "user_days_reorder = user_days_reorder.rename(columns={'days_reorder':'user_days_reorder'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 13 user average mean reorder per days since prior order\n",
    "X_train = X_train.merge(user_days_reorder, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Department Ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The department ratio indicates whether the user shops from many departments in each order he places. If he does that makes him more likely to include beverages in his next order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create department columns in prior orders frame\n",
    "orders_priors = orders_priors.merge(products[['product_id', 'department_id']], on = 'product_id', how='left')\n",
    "unique_deps = orders_priors.groupby('order_id')['department_id'].nunique().reset_index()\n",
    "unique_deps = unique_deps.rename(columns={'department_id':'unique_deps'})\n",
    "orders_priors = orders_priors.merge(unique_deps, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of how many departments did the user shop from in relation to total departments per order\n",
    "orders_priors['department_ratio']= orders_priors['unique_deps']/num_deps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_priors_bev = orders_priors_bev.merge(orders_priors[['order_id', 'department_ratio']].drop_duplicates(subset=['order_id']), on='order_id', how='left')\n",
    "orders_bev = orders_bev.merge(orders_priors_bev[['order_id','department_ratio']].drop_duplicates(subset=['order_id']), on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average user department ratio\n",
    "user_department_ratio = orders_bev.groupby('user_id')['department_ratio'].mean().reset_index()\n",
    "user_department_ratio = user_department_ratio.rename(columns={'department_ratio':'user_department_ratio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature14 average user department ratio\n",
    "X_train = X_train.merge(user_department_ratio, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aisles Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aisles ratio is also a measure that indicates variety since the more aisles the user roams in every order the more likely he is to have a wide range of products in his basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create aisles columns in prior orders frame\n",
    "orders_priors = orders_priors.merge(products[['product_id', 'aisle_id']], on='product_id', how='left')\n",
    "unique_aisles = orders_priors.groupby('order_id')['aisle_id'].nunique().reset_index()\n",
    "unique_aisles = unique_aisles.rename(columns={'aisle_id':'unique_aisles'})\n",
    "orders_priors = orders_priors.merge(unique_aisles, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of how many aisles did the user shop from in relation to total aisles per order\n",
    "orders_priors_bev = orders_priors_bev.merge(products[['product_id', 'aisle_id']], on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of how many aisles did the user shop from in relation to total aisles per order\n",
    "orders_priors['aisles_ratio']= orders_priors['unique_aisles']/num_aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average user aisle ratio\n",
    "orders_priors_bev = orders_priors_bev.merge(orders_priors[['order_id','aisles_ratio']].drop_duplicates(subset=['order_id']), on='order_id', how='left')\n",
    "orders_bev = orders_bev.merge(orders_priors_bev[['order_id','aisles_ratio']].drop_duplicates(subset=['order_id']), on='order_id', how='left')\n",
    "user_aisles_ratio = orders_bev.groupby('user_id')['aisles_ratio'].mean().reset_index()\n",
    "user_aisles_ratio = user_aisles_ratio.rename(columns={'aisles_ratio':'user_aisles_ratio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 15 average user aisle ratio\n",
    "X_train = X_train.merge(user_aisles_ratio, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to cart early per user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider the relation between the order in which the user places a product in the cart with the possibility that this product is reordered. To do so, we can plot the average reorder ratio per add to cart order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_add = orders_priors_bev.copy()\n",
    "reorder_add['add_to_cart_order'] = np.where(reorder_add['add_to_cart_order']>60, 60, reorder_add['add_to_cart_order'])\n",
    "\n",
    "grouped_df = reorder_add.groupby([\"add_to_cart_order\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(grouped_df['add_to_cart_order'].values, grouped_df['reordered'].values, alpha=0.5, color='red')\n",
    "plt.ylabel('Reorder ratio', fontsize=12)\n",
    "plt.xlabel('Add to cart order', fontsize=12)\n",
    "\n",
    "plt.title(\"Add to cart reorder ratio\", fontsize=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig('Add to cart reorder ratio.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the diagram there is a relation between the order the customer places beverages to the cart with the possibility of reordering them. We can assume that this is reasonably true for all the products since we are talking about an e-shop and considering that we place first the products that we usually buy whereas in a physical store the order in which we put products to the cart dependes on how the aisles are shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average reorder per add to cart order\n",
    "grouped_df = orders_priors_bev.groupby([\"add_to_cart_order\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "grouped_df = grouped_df.rename(columns={'reordered':'prob_reorder_add_to_cart'})\n",
    "orders_priors_bev = orders_priors_bev.merge(grouped_df, on='add_to_cart_order', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_prod_df = orders_bev.merge(orders_priors_bev, on='order_id', how='left')\n",
    "prob_add = orders_prod_df.groupby('user_id')['prob_reorder_add_to_cart'].mean().reset_index()\n",
    "orders_bev = orders_bev.merge(prob_add.drop_duplicates(subset=['user_id']), on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_prob_reorder_add_to_cart = orders_bev.groupby('user_id')['prob_reorder_add_to_cart'].mean().reset_index()\n",
    "user_prob_reorder_add_to_cart = user_prob_reorder_add_to_cart.rename(columns={'prob_reorder_add_to_cart':'user_prob_reorder_add_to_cart'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 16 user average reorder per add to cart order\n",
    "X_train = X_train.merge(user_prob_reorder_add_to_cart, on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Beverages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the beverages has the user purchased before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate how many of the unique beverages code the user has shopped from\n",
    "orders_products_df = orders_bev.merge(orders_priors_bev, on='order_id', how='left')\n",
    "bev_rt = orders_products_df.groupby('user_id')['product_id'].nunique().reset_index()\n",
    "bev_rt = bev_rt.rename(columns={'product_id':'bev_unique'})\n",
    "orders_bev = orders_bev.merge(bev_rt, on='user_id', how='left')\n",
    "orders_bev['bev_rt']= orders_bev['bev_unique']/num_bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 18 unique beverages ratio\n",
    "X_train = X_train.merge(orders_bev[['user_id', 'bev_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder Bev vs Reorder Prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of reordered beverages vs reordered products can indicate the tendency of the user of reordering beverages is stronger than this of reordering other products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev['bev_prod_reorder_rt']= orders_bev['reordered_bev_count']/orders_bev['reordered_prod_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 19 beverages reordered versus product reordered ratio\n",
    "X_train = X_train.merge(orders_bev[['user_id', 'bev_prod_reorder_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimate in which day do the most orders appear per user\n",
    "days_rt = orders_bev.groupby('user_id')['order_dow'].nunique().reset_index()\n",
    "days_rt = days_rt.rename(columns={'order_dow':'shopping_days'})\n",
    "orders_bev = orders_bev.merge(days_rt, on='user_id', how='left')\n",
    "orders_bev['days_rt']= orders_bev['shopping_days']/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 20 days ratio per user\n",
    "X_train = X_train.merge(orders_bev[['user_id','days_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimate in which hour do the most orders appear per user\n",
    "hours_rt = orders_bev.groupby('user_id')['order_hour_of_day'].nunique().reset_index()\n",
    "hours_rt = hours_rt.rename(columns={'order_hour_of_day':'shopping_hours'})\n",
    "orders_bev = orders_bev.merge(hours_rt, on='user_id', how='left')\n",
    "orders_bev['hours_rt']= orders_bev['shopping_hours']/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 21 hours ratio per user\n",
    "X_train = X_train.merge(orders_bev[['user_id','hours_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aisles of department 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the ratio of from how many of the aisles of the department 7 has the user shopped from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_aisles = orders_bev.merge(orders_priors_bev[['order_id', 'aisle_id']], on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aisles_7 = orders_aisles.groupby('user_id')['aisle_id'].nunique().reset_index()\n",
    "aisles_7 = aisles_7.rename(columns={'aisle_id':'unique_aisles_7'})\n",
    "num_aisles_7 = products_bev.aisle_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(aisles_7, on='user_id', how='left')\n",
    "orders_bev['aisles_7_ratio']=orders_bev['unique_aisles_7']/num_aisles_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 22 unique aisles of dep 7 per user\n",
    "X_train = X_train.merge(orders_bev[['user_id','aisles_7_ratio']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Departments of User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total how many of the departments has the user shopped from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_deps = orders.merge(orders_priors[['order_id', 'department_id']], on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate from how many unique departments has the user shopped from \n",
    "deps = orders_deps.groupby('user_id')['department_id'].nunique().reset_index()\n",
    "deps = deps.rename(columns={'department_id':'unique_dpts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_bev = orders_bev.merge(deps, on='user_id', how='left')\n",
    "orders_bev['dpts_ratio']=orders_bev['unique_dpts']/num_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 23 unique departments per user\n",
    "X_train = X_train.merge(orders_bev[['user_id','dpts_ratio']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_train = X_train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['order_id','user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=pd.read_csv(\"data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['order_dow', 'order_hour_of_day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 2 bev_orders/orders per user\n",
    "X_test  = X_test.merge(count_ord_bev[['user_id', 'orders_bev_ratio']], on='user_id', how='left')\n",
    "X_test  = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 3 beverages orders per user\n",
    "#X_test = X_test.merge(count_ord_bev[['user_id', 'order_count']], on='user_id', how='left')\n",
    "#X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 4 orders per user\n",
    "#X_test = X_test.merge(count_ord_bev[['user_id', 'orders_count']], on='user_id', how='left')\n",
    "#X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 5 average beverage per basket per user\n",
    "X_test = X_test.merge(bev_per_basket, on='user_id', how='left')\n",
    "X_test  = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 6 mean beverages count per user\n",
    "X_test = X_test.merge(beverages, on='user_id', how='left')\n",
    "X_test  = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 7 size of order\n",
    "#X_test = X_test.merge(orders_bev[['user_id','size_of_order' ]].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "#X_test  = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 8 user average ratio of beverages that are reordered\n",
    "X_test = X_test.merge(user_reorder_bev_ratio, on='user_id', how='left')\n",
    "X_test  = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 9 user average ratio of bev per basket that are reordered\n",
    "X_test = X_test.merge(user_reorder_bev_basket_rt, on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 10 average user product reorder ratio \n",
    "X_test = X_test.merge(user_reorder_ratio, on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 11 average interval ratio bev/prod\n",
    "X_test = X_test.merge(average_order_days_bev[['user_id', 'avg_days_bev']], on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 12 average interval between buying products per user\n",
    "X_test = X_test.merge(average_order_days_bev[['user_id', 'avg_days_since_prior']], on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 13 user average mean reorder per days since prior order\n",
    "X_test = X_test.merge(user_days_reorder, on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature14 average user department ratio\n",
    "X_test = X_test.merge(user_department_ratio, on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 15 average user aisle ratio\n",
    "X_test = X_test.merge(user_aisles_ratio, on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 16 user average reorder per add to cart order\n",
    "#X_test = X_test.merge(user_prob_reorder_add_to_cart, on='user_id', how='left')\n",
    "#X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 18 unique beverages ratio\n",
    "#X_test = X_test.merge(orders_bev[['user_id', 'bev_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "#X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 19 beverages reordered versus product reordered ratio\n",
    "#X_test = X_test.merge(orders_bev[['user_id', 'bev_prod_reorder_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "#X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 20 days ratio per user\n",
    "X_test = X_test.merge(orders_bev[['user_id','days_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 21 hours ratio per user\n",
    "X_test = X_test.merge(orders_bev[['user_id','hours_rt']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 22 unique aisles of dep 7 per user\n",
    "X_test = X_test.merge(orders_bev[['user_id','aisles_7_ratio']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature 23 unique departments per user\n",
    "X_test = X_test.merge(orders_bev[['user_id','dpts_ratio']].drop_duplicates(subset=['user_id']), on='user_id', how='left')\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['order_id','user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to establish how many of the features we extracted previously are usefull. This can be achieved with 2 methods among others: Decision Trees and Correlation between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X_train, y_train, test_size=0.33)\n",
    "forest = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_tr, y_tr[\"category\"])\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_tr.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_tr.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_tr.shape[1]), indices)\n",
    "plt.xlim([-1, X_tr.shape[1]])\n",
    "plt.savefig('Feature_importances 23 features.png')\n",
    "plt.show()\n",
    "y_pred = forest.predict(X_tst)\n",
    "print(\"extratrees\",accuracy_score(y_tst[\"category\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine that feature 18 unique beverages per user is worthless and therefore remove it. We can also remove feature 3 beverages orders  19 beverages reordered versus product reordered ratio as they don't really contribute to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "features_corr = X_train.corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))         # Sample figsize in inches\n",
    "# plot the heatmap\n",
    "sns.heatmap(features_corr, \n",
    "        xticklabels=features_corr.columns,\n",
    "        yticklabels=features_corr.columns,annot=True, linewidths=.5)\n",
    "plt.savefig(\"corrrelation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation matrix we can determine that feature  user average of beverages added early in the cart is highly correlated with feature 5 beverages per basket as well as size of orders feature 7 is highly correlated with  aisles ratio feature 15 and therefore we can remove them since they are also lower in the feature importance rank. Another highly correlated feature is feature 4 orders count to feature 1 order number. Since order number is higher in the feature importance rank we drop feature 4 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['order_count', 'bev_rt', 'bev_prod_reorder_rt', 'size_of_order'], axis=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['orders_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that are finally selected are the following:\n",
    "- order number\n",
    "- days since prior order\n",
    "- orders beverages ratio\n",
    "- beverages per basket ratio\n",
    "- mean beverages count per user\n",
    "- user beverage per basket reorder ratio\n",
    "- user beverage reorder ratio \n",
    "- average days between beverages orders\n",
    "- average days between orders\n",
    "- average reorder per days since prior order\n",
    "- user department ratio\n",
    "- user aisles ratio\n",
    "- days ratio\n",
    "- hours ratio\n",
    "- aisles of department 7 ratio\n",
    "- unique departments ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider 4 different classifiers for the task\n",
    "\n",
    "- Logistic Regression Classifier\n",
    "- Xgboost Classifier\n",
    "- Random Forests Classifier\n",
    "- Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test evaluate\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X_train, y_train, test_size=0.33)\n",
    "\n",
    "X_tr_scaled = preprocessing.scale(X_tr)\n",
    "X_tst_scaled = preprocessing.scale(X_tst)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_tr_scaled, y_tr[\"category\"])\n",
    "y_pred = logreg.predict(X_tst_scaled)\n",
    "print(\"logreg\",accuracy_score(y_tst[\"category\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = preprocessing.scale(X_train) \n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "model_logreg = LogisticRegression()\n",
    "model_logreg.fit(X_train_scaled, y_train[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['category'] = logreg.predict(X_test_scaled)\n",
    "X_test['category'] = np.round(X_test['category']).astype(int)\n",
    "X_tmp = pd.read_csv(\"data/X_test.csv\")\n",
    "submission = pd.concat([X_tmp['order_id'], X_test['category']], axis=1)\n",
    "submission.to_csv(\"logreg_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XgBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test evaluate\n",
    "xgb = xgboost.XGBClassifier()\n",
    "\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X_train, y_train, test_size=0.33)\n",
    "xgb.fit(X_tr, y_tr[\"category\"])\n",
    "y_pred_xgb = xgb.predict(X_tst)\n",
    "print(\"xgboost\",accuracy_score(y_tst[\"category\"], y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train[\"category\"])\n",
    "X_test['category'] = xgb.predict(X_test)\n",
    "X_test['category'] = np.round(X_test['category']).astype(int)\n",
    "X_tmp = pd.read_csv(\"data/X_test.csv\")\n",
    "submission = pd.concat([X_tmp['order_id'], X_test['category']], axis=1)\n",
    "submission.to_csv(\"xgboost_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_score_xgb = 0.617448652"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test evaluate\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X_train, y_train, test_size=0.33)\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X_tr, y_tr['category'])\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=250, n_jobs=8)\n",
    "random_forest.fit(X_train, y_train[\"category\"])\n",
    "X_test['category'] = random_forest.predict(X_test)\n",
    "X_test['category'] = np.round(X_test['category']).astype(int)\n",
    "X_tmp = pd.read_csv(\"data/X_test.csv\")\n",
    "submission = pd.concat([X_tmp['order_id'], X_test['category']], axis=1)\n",
    "submission.to_csv(\"rand_for_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a simple neural network since our number of features is not that high to justify a deep learning approach. The neural network is comprised of the input layer, a middle layer with 17 units (same as the number of features) and tanh as activation and the output layer with a sigmoid function as activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X_train, y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(17, input_dim=17, init = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5000, batch_size=X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_tst, y_tst)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['category'] = model.predict(X_test)\n",
    "X_test['category'] = np.round(X_test['category']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tmp = pd.read_csv(\"data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([X_tmp['order_id'], X_test['category']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"neuralnet_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_score_nn = 0.618340827681"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy score in the submission file was given by the neural network and was 61,83%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
